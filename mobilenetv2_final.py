# -*- coding: utf-8 -*-
"""Mobilenetv2-try.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tjGTwajhBQRVZ5gjKHojT7lL5g9HHOl-
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle

cp "kaggle.json" ~/.kaggle/kaggle.json

!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d arjuntejaswi/plant-village

! unzip /content/plant-village.zip

! rm /content/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus/svn-r6Yb5c

import os
# Define the path to remove
path_to_remove = "/content/PlantVillage/Tomato__Tomato_YellowLeaf__Curl_Virus/svn-r6Yb5c"

# Remove the file or directory
if os.path.exists(path_to_remove):
    if os.path.isdir(path_to_remove):
        shutil.rmtree(path_to_remove)
        print(f"Directory {path_to_remove} has been removed.")
    else:
        os.remove(path_to_remove)
        print(f"File {path_to_remove} has been removed.")
else:
    print(f"Path {path_to_remove} does not exist.")

!ls /content/PlantVillage

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import os
from google.colab import files

# Define constants
BATCH_SIZE = 32
IMAGE_SIZE = 224  # MobileNetV2 default size
CHANNELS = 3
EPOCHS = 10

# Load dataset
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/PlantVillage",
    seed=123,
    shuffle=True,
    image_size=(IMAGE_SIZE, IMAGE_SIZE),
    batch_size=BATCH_SIZE
)

class_names = dataset.class_names
class_names

len(class_names)

plt.figure(figsize=(15, 10))
for image_batch, labels_batch in dataset.take(1):
    for i in range(12):
        ax = plt.subplot(3, 4, i + 1)
        plt.imshow(image_batch[i].numpy().astype("uint8"))
        plt.title(class_names[labels_batch[i]])
        plt.axis("off")

# Function to partition dataset
def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):
    assert (train_split + val_split + test_split) == 1

    ds_size = len(ds)
    if shuffle:
        ds = ds.shuffle(shuffle_size, seed=12)

    train_size = int(train_split * ds_size)
    val_size = int(val_split * ds_size)

    train_ds = ds.take(train_size)
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size).skip(val_size)

    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)

# Apply resizing and rescaling
resize_and_rescale = tf.keras.Sequential([
    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),
    layers.Rescaling(1./255)
])

train_ds = train_ds.map(lambda x, y: (resize_and_rescale(x), y))
val_ds = val_ds.map(lambda x, y: (resize_and_rescale(x), y))
test_ds = test_ds.map(lambda x, y: (resize_and_rescale(x), y))

# Define data augmentation
augmentation_layers_list = ([
    layers.RandomFlip("horizontal_and_vertical"),  # Flip horizontally and vertically
    layers.RandomRotation(0.2),                    # Rotate by up to 20%
    layers.RandomTranslation(0.1, 0.1),            # Translate by up to 10% horizontally and vertically
    layers.RandomZoom(0.2, 0.2),                   # Zoom in/out by up to 20%
    layers.RandomBrightness(factor=0.2),           # Adjust brightness by +/- 20%
    layers.RandomContrast(factor=0.2),             # Adjust contrast by +/- 20%
    layers.GaussianNoise(0.1),                     # Add Gaussian noise
    layers.RandomCrop(256, 256),                   # Randomly crop to 256x256 (if needed)
    layers.Rescaling(1./255)                       # Normalize to [0,1] range,
])

# Sequential model for applying the augmentations
augmentation_layers = tf.keras.Sequential(augmentation_layers_list)

plt.figure(figsize=(18, 10))
for images, labels in dataset.take(1):
  for i in range(12):
    augmented_image = augmentation_layers(image_batch[i].numpy().astype("uint8"))
    ax = plt.subplot(4, 3, i + 1)
    label = class_names[labels[i]]
    augmentation_layer = augmentation_layers_list[i % len(augmentation_layers_list)]
    plt.imshow(augmented_image.numpy())
    plt.title(f"{label} - {augmentation_layer.__class__.__name__}")
    plt.axis("off")
plt.savefig("augmented_images.png")
files.download("augmented_images.png")

# Function to apply a single augmentation layer
def apply_augmentation(image, layer):
    image = tf.expand_dims(image, axis=0)  # Add batch dimension
    image = tf.cast(image, tf.float32)  # Convert image to float32
    augmented_image = layer(image, training=True)
    return tf.squeeze(augmented_image, axis=0)  # Remove batch dimension

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)

def build_model(input_shape, num_classes):
    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')
    base_model.trainable = False

    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dropout(0.2),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])

    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)
num_classes = len(class_names)

model = build_model(input_shape, num_classes)

model.summary()

from tensorflow.keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=[early_stopping]
)

# Evaluate the model on the test dataset
test_loss, test_acc = model.evaluate(test_ds)
print(f"Test accuracy: {test_acc * 100:.2f}%")

scores2 = model.evaluate(val_ds)

# Save the model
model.save('mobilenetv2_plant_disease.h5')

def plot_metrics(history):
    plt.figure(figsize=(12, 4))

    # Plot training & validation accuracy values
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(loc='upper left')

    # Plot training & validation loss values
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(loc='upper left')

    plt.tight_layout()
    plt.show()

    # Check for overfitting
    train_acc = history.history['accuracy'][-1]
    val_acc = history.history['val_accuracy'][-1]
    train_loss = history.history['loss'][-1]
    val_loss = history.history['val_loss'][-1]

    print(f"Final Training Accuracy: {train_acc:.4f}")
    print(f"Final Validation Accuracy: {val_acc:.4f}")
    print(f"Final Training Loss: {train_loss:.4f}")
    print(f"Final Validation Loss: {val_loss:.4f}")

    if train_acc > val_acc and (train_acc - val_acc) > 0.1:
        print("Potential overfitting detected: Training accuracy is significantly higher than validation accuracy.")
    if train_loss < val_loss and (val_loss - train_loss) > 0.1:
        print("Potential overfitting detected: Training loss is significantly lower than validation loss.")

    # You can further analyze trends to confirm overfitting.
    if all([val_acc < acc for acc in history.history['accuracy'][-3:]]):
        print("Validation accuracy is not improving over last epochs, indicating potential overfitting.")


        # Check for overfitting
    acc_diff = np.array(history.history['accuracy']) - np.array(history.history['val_accuracy'])
    loss_diff = np.array(history.history['loss']) - np.array(history.history['val_loss'])

    overfitting_detected = np.any(acc_diff > 0.1) or np.any(loss_diff < -0.1)
    if overfitting_detected:
        print("Overfitting detected: Training accuracy significantly higher than validation accuracy, or validation loss is increasing.")
    else:
        print("No overfitting detected: Model generalizes well to validation data.")

plot_metrics(history)

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# PrÃ©dire les classes pour l'ensemble de test
y_true = []
y_pred = []

for images, labels in test_ds:
    predictions = model.predict(images)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(predictions, axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Construire la matrice de confusion
cm = confusion_matrix(y_true, y_pred)

# Afficher la matrice de confusion
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Afficher le rapport de classification
print(classification_report(y_true, y_pred, target_names=class_names))

from tensorflow.keras.preprocessing import image

# Define a function to preprocess the image
def preprocess_image(img_path, target_size):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array = img_array / 255.0  # Rescale
    return img_array

# Load a sample image
img_path = '/content/Pepper bell Bacterial spot.jpg'
img_array = preprocess_image(img_path, target_size=(224, 224))

# Make predictions
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions, axis=1)

# Visualize the prediction
plt.imshow(image.load_img(img_path))
plt.title(f"Predicted: {class_names[predicted_class[0]]}")
plt.axis('off')
plt.show()

!pip install visualkeras

import visualkeras

visualkeras.layered_view(model).show() # display using your system viewer
visualkeras.layered_view(model, to_file='output.png') # write to disk
visualkeras.layered_view(model, to_file='output.png').show() # write and show

visualkeras.layered_view(model)

!pip install keras_sequential_ascii

from keras_sequential_ascii import keras2ascii
keras2ascii(model)

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
import tensorflow as tf
from tensorflow.keras.callbacks import TensorBoard
import datetime

# DÃ©finir un rÃ©pertoire pour les logs de TensorBoard
log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS,
    callbacks=[tensorboard_callback]
)

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/fit

from sklearn.manifold import TSNE
from sklearn.decomposition import PCA

# SÃ©lectionner une couche intermÃ©diaire
layer_name = 'global_average_pooling2d'
intermediate_layer_model = tf.keras.models.Model(inputs=model.input,
                                                 outputs=model.get_layer(layer_name).output)

# Obtenir les activations pour un lot d'images
for images, labels in test_ds.take(1):
    intermediate_output = intermediate_layer_model(images)

# RÃ©duction de dimension avec PCA ou t-SNE
pca = PCA(n_components=3)
tsne = TSNE(n_components=3)

pca_result = pca.fit_transform(intermediate_output)
tsne_result = tsne.fit_transform(intermediate_output)

# Visualisation 3D avec matplotlib
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(12, 6))

# PCA
ax1 = fig.add_subplot(121, projection='3d')
ax1.scatter(pca_result[:, 0], pca_result[:, 1], pca_result[:, 2], c=labels, cmap='viridis')
ax1.set_title('PCA Projection')

# t-SNE
ax2 = fig.add_subplot(122, projection='3d')
ax2.scatter(tsne_result[:, 0], tsne_result[:, 1], tsne_result[:, 2], c=labels, cmap='viridis')
ax2.set_title('t-SNE Projection')

plt.show()



